2023-05-07 16:12:43.599067: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-05-07 16:12:45.339216: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-07 16:12:55.767422: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-05-07 16:13:36.739988: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [93]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:36.879736: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [109]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:36.941365: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [73]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:37.002387: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [100]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:37.062792: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [105]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:37.124188: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [103]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:37.186359: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [107,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:37.248002: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [85]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:37.308630: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [109]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:37.369614: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [88]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:37.430470: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [106]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:37.493433: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [96,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:37.555729: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [101]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:37.617634: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [95,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:37.676993: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [75]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:37.736720: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [93]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:37.796587: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [106]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:37.859184: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [92]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:37.919890: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [115,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:37.979197: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [72]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:38.040097: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [87]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:38.100087: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [106,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:38.166181: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [96,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:38.235827: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [74,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:38.302655: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [103]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:38.371443: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [54]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:38.438516: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [107,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:38.504405: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [16]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:38.564414: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [111]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:38.626262: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [106,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:38.685340: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [106]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:38.743551: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [110,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:38.804806: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [108]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:38.863771: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [101,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:38.922185: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [83,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:38.981016: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [113,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:39.039693: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [70]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:39.096820: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [84,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:39.155016: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [109]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:39.214644: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [77,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:39.273839: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [87]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:39.334368: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [99,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:39.393265: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [106]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:39.452034: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [90]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:39.511294: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [68]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:39.570127: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [93,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:39.628973: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [95]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:39.688625: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [75,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:39.959694: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [101,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:40.018035: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [96]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:40.081895: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [105,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:40.148715: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [97,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:40.215440: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [112,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:40.282926: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [108,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:40.354962: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [98,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:40.418188: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [105]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:40.477529: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [90]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:40.537127: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [114]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:40.596287: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [103]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:40.654956: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [99,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:40.717089: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [107,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:40.777129: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [105,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:40.836102: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [104]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:40.895237: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [114]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:40.954126: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [91]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:41.012278: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [104]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:41.075515: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [92]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:41.134625: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [114,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:41.195969: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [91]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:41.255701: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [84]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:41.312950: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [97,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:41.370482: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [115,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:41.430844: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [75]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:41.488665: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [107,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:41.545601: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [84]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:41.601556: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [70]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:41.657980: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [106]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:41.715537: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [102]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:41.777809: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [91]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:41.837412: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [64]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:41.896566: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [106]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:41.954887: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [62,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:42.011584: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [114]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:42.074268: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [89,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:42.137558: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [81]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:42.194517: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [42]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:42.252917: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [85,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:42.311320: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [72,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:42.369871: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [94]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:42.438117: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [106,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:42.500980: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [110,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:42.560430: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [103,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:42.619318: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [109]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:42.679226: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [100,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:42.738236: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [109]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:42.795098: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [78]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:42.853105: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [96]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:42.912799: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [93]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:42.971089: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [84,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:43.029787: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [97]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:43.129479: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [109,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:43.129751: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [84]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:43.129844: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [96,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:43.129941: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [91]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:43.129980: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [95,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:13:43.130128: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [89]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:43.130163: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [88]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:43.130219: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [106]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:43.130454: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [106]
	 [[{{node Placeholder/_1}}]]
2023-05-07 16:13:43.130891: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [107,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 16:22:29.650710: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x2b4ce01e2830 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2023-05-07 16:22:29.650789: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): Host, Default Version
2023-05-07 16:22:34.125870: W tensorflow/compiler/tf2xla/kernels/random_ops.cc:102] Warning: Using tf.random.uniform with XLA compilation will ignore seeds; consider using tf.random.stateless_uniform instead if reproducible behavior is desired. StatefulPartitionedCall/random_uniform
2023-05-07 16:22:34.423800: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-05-07 16:24:53.517439: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_598343__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 16:25:01.193165: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_598832__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 16:25:04.688486: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_599001__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 16:25:05.534188: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_599203__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 16:25:06.433449: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_599382__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 16:25:09.913055: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_599449__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 16:25:41.794668: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m48.2804167s

********************************
[Compiling module a_inference_run_step_598343__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 16:25:41.795178: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2023-05-07 16:25:45.372401: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m47.663132786s

********************************
[Compiling module a_inference_run_step_598535__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 16:25:46.663631: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m48.716679572s

********************************
[Compiling module a_inference_run_step_598602__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 16:25:50.681133: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m49.488165859s

********************************
[Compiling module a_inference_run_step_598832__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 16:25:53.530488: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m47.097105816s

********************************
[Compiling module a_inference_run_step_599382__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 16:25:54.177268: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m46.631154703s

********************************
[Compiling module a_inference_run_step_599516__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 16:25:54.562582: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m51.231976154s

********************************
[Compiling module a_inference_run_step_598993__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 16:25:55.918647: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m50.385182418s

********************************
[Compiling module a_inference_run_step_599203__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 16:25:56.596546: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m51.908221049s

********************************
[Compiling module a_inference_run_step_599001__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 16:26:02.333152: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m52.420358834s

********************************
[Compiling module a_inference_run_step_599449__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 16:28:20.759474: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_598343__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 16:28:24.661214: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_598535__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 16:28:28.176395: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_598602__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 16:28:34.024158: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_599382__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 16:28:34.746215: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_598993__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 16:28:35.943265: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_599001__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 16:28:37.371225: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_599203__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 16:28:42.360972: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_599449__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 16:29:31.450162: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m10.690796716s

********************************
[Compiling module a_inference_run_step_598343__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 16:29:38.835281: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m14.174165983s

********************************
[Compiling module a_inference_run_step_598535__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 16:29:40.177810: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m3.753641624s

********************************
[Compiling module a_inference_run_step_599516__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 16:29:42.110331: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m6.167103817s

********************************
[Compiling module a_inference_run_step_599001__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 16:29:43.092393: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m8.346254774s

********************************
[Compiling module a_inference_run_step_598993__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 16:31:04.794001: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m36.617669343s

********************************
[Compiling module a_inference_run_step_598602__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 16:31:05.825564: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m31.801498709s

********************************
[Compiling module a_inference_run_step_599382__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 16:31:14.621591: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m37.250441002s

********************************
[Compiling module a_inference_run_step_599203__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 16:31:27.253144: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m44.892222268s

********************************
[Compiling module a_inference_run_step_599449__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:02:01.106226: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [72]
	 [[{{node Placeholder/_1}}]]
2023-05-07 17:02:01.112650: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [64]
	 [[{{node Placeholder/_1}}]]
2023-05-07 17:02:01.128468: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [75,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 17:02:01.130488: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [81]
	 [[{{node Placeholder/_1}}]]
2023-05-07 17:02:01.133502: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [114]
	 [[{{node Placeholder/_1}}]]
2023-05-07 17:02:01.134097: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [70]
	 [[{{node Placeholder/_1}}]]
2023-05-07 17:02:01.134191: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [114]
	 [[{{node Placeholder/_1}}]]
2023-05-07 17:02:01.136544: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [93]
	 [[{{node Placeholder/_1}}]]
2023-05-07 17:13:59.014439: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_1165777__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:14:05.938004: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_1166502__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:14:06.373276: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_1166310__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:14:06.574572: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_1166485__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:14:06.705585: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_1166467__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:14:06.900073: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_1166406__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:14:07.184835: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_1166434__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:14:07.984081: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_1166725__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:14:38.370465: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m39.361323193s

********************************
[Compiling module a_inference_run_step_1165777__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:14:44.575740: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m38.001789571s

********************************
[Compiling module a_inference_run_step_1166485__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:14:46.182975: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m40.24516562s

********************************
[Compiling module a_inference_run_step_1166502__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:14:47.289122: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m40.583970931s

********************************
[Compiling module a_inference_run_step_1166467__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:14:47.555047: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m40.371031837s

********************************
[Compiling module a_inference_run_step_1166434__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:14:48.340976: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m41.968864674s

********************************
[Compiling module a_inference_run_step_1166310__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:14:49.222869: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m42.323368428s

********************************
[Compiling module a_inference_run_step_1166406__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:14:51.481007: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m43.498933478s

********************************
[Compiling module a_inference_run_step_1166725__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:17:34.357807: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_1166434__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:17:36.660816: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_1166310__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:17:37.054760: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_1166467__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:17:37.806927: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_1166502__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:17:38.721360: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_1166406__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:18:37.421449: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m3.063796029s

********************************
[Compiling module a_inference_run_step_1166434__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:18:39.112964: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m1.306105992s

********************************
[Compiling module a_inference_run_step_1166502__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:18:40.918596: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m2.197317097s

********************************
[Compiling module a_inference_run_step_1166406__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:18:41.874660: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m5.213917347s

********************************
[Compiling module a_inference_run_step_1166310__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:18:42.520319: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m1.200777239s

********************************
[Compiling module a_inference_run_step_1166725__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:20:24.234755: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m47.179801637s

********************************
[Compiling module a_inference_run_step_1166467__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:42:30.502422: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [105]
	 [[{{node Placeholder/_1}}]]
2023-05-07 17:42:30.517260: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [105]
	 [[{{node Placeholder/_1}}]]
2023-05-07 17:42:30.518226: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [97,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 17:42:30.518427: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [85,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 17:42:30.518687: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [105]
	 [[{{node Placeholder/_1}}]]
2023-05-07 17:42:30.519349: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [99,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 17:42:30.519632: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [106,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 17:42:30.519740: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [109]
	 [[{{node Placeholder/_1}}]]
2023-05-07 17:54:28.995492: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_1721375__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:54:31.994334: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_1721855__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:54:32.662365: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_1721770__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:54:32.798273: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_1721780__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:54:33.773952: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_1722087__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:54:33.797762: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_1722283__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:54:34.152575: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_1722118__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:54:34.276474: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_1722204__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:55:10.322591: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m41.327340502s

********************************
[Compiling module a_inference_run_step_1721375__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:55:13.537183: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m41.549667746s

********************************
[Compiling module a_inference_run_step_1721855__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:55:14.746899: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m42.085851113s

********************************
[Compiling module a_inference_run_step_1721770__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:55:15.958550: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m42.160986925s

********************************
[Compiling module a_inference_run_step_1722283__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:55:16.108077: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m43.310255168s

********************************
[Compiling module a_inference_run_step_1721780__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:55:16.550312: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m42.778802888s

********************************
[Compiling module a_inference_run_step_1722087__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:55:17.138541: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m42.986045351s

********************************
[Compiling module a_inference_run_step_1722118__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:55:17.637966: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m43.361925588s

********************************
[Compiling module a_inference_run_step_1722204__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_train_function.<locals>.train_function at 0x2b4caa0a5430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x2b4caa059670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
2023-05-07 17:57:58.436719: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_1721375__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:58:10.354951: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_1721855__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:58:12.137054: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_1721770__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:58:13.337969: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_1722283__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:59:48.320492: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m37.965652825s

********************************
[Compiling module a_inference_run_step_1721855__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 17:59:57.996092: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m59.559498398s

********************************
[Compiling module a_inference_run_step_1721375__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 18:00:14.787612: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m1.449698117s

********************************
[Compiling module a_inference_run_step_1722283__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 18:01:33.669392: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 5m21.532421782s

********************************
[Compiling module a_inference_run_step_1721770__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 18:32:45.257899: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [87,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 18:32:45.271344: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [92,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 18:32:45.282813: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [90]
	 [[{{node Placeholder/_1}}]]
2023-05-07 18:32:45.285771: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [107,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 18:32:45.286644: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [104,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 18:32:45.287359: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [114]
	 [[{{node Placeholder/_1}}]]
2023-05-07 18:32:45.297196: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [62]
	 [[{{node Placeholder/_1}}]]
2023-05-07 18:47:53.089717: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_2225845__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 18:47:54.320541: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_2226078__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 18:47:55.215211: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_2225940__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 18:47:55.761620: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_2225917__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 18:47:55.916847: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_2226169__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 18:47:57.621917: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_2226297__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 18:47:58.460810: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_2226155__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 18:48:44.625723: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m51.538386875s

********************************
[Compiling module a_inference_run_step_2225845__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 18:48:46.241760: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m51.924265751s

********************************
[Compiling module a_inference_run_step_2226078__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 18:48:54.054878: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m58.138531269s

********************************
[Compiling module a_inference_run_step_2226169__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 18:48:54.628863: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m59.41589576s

********************************
[Compiling module a_inference_run_step_2225940__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 18:48:55.702716: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m59.94251608s

********************************
[Compiling module a_inference_run_step_2225917__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 18:48:57.004168: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m58.545485352s

********************************
[Compiling module a_inference_run_step_2226155__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 18:48:57.036797: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m59.415026471s

********************************
[Compiling module a_inference_run_step_2226297__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 18:51:20.786083: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_2225845__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 18:51:27.042124: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_2226078__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 18:51:34.380471: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_2226297__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 18:51:36.921231: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_2225940__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 18:51:38.227579: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_2225917__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 18:51:40.153018: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_2226155__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 18:52:04.180002: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m43.394170655s

********************************
[Compiling module a_inference_run_step_2225845__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 18:52:15.034569: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m47.992584587s

********************************
[Compiling module a_inference_run_step_2226078__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 18:52:21.341358: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m46.960979338s

********************************
[Compiling module a_inference_run_step_2226297__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 18:52:23.382927: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m46.461172552s

********************************
[Compiling module a_inference_run_step_2225940__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 18:52:24.977690: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m46.750199902s

********************************
[Compiling module a_inference_run_step_2225917__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 18:52:25.566466: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m45.413526465s

********************************
[Compiling module a_inference_run_step_2226155__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 19:19:00.236108: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [96]
	 [[{{node Placeholder/_1}}]]
2023-05-07 19:19:00.237555: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [90]
	 [[{{node Placeholder/_1}}]]
2023-05-07 19:19:00.237671: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [92,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 19:19:00.237776: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [113]
	 [[{{node Placeholder/_1}}]]
2023-05-07 19:19:00.244891: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [110]
	 [[{{node Placeholder/_1}}]]
2023-05-07 19:19:00.245063: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [85]
	 [[{{node Placeholder/_1}}]]
2023-05-07 19:19:00.246567: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [83]
	 [[{{node Placeholder/_1}}]]
2023-05-07 19:19:00.250354: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [97,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 19:31:05.354794: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_2781078__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 19:31:09.877960: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_2781270__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 19:31:11.999783: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_2781387__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 19:31:13.107619: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_2781664__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 19:31:13.206427: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_2781616__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 19:31:13.677665: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_2781865__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 19:31:14.152153: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_2781872__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 19:31:42.615172: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m37.260585811s

********************************
[Compiling module a_inference_run_step_2781078__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 19:31:44.711808: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m34.834051423s

********************************
[Compiling module a_inference_run_step_2781270__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 19:31:48.360898: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m34.683376491s

********************************
[Compiling module a_inference_run_step_2781865__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 19:31:49.641924: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m37.646495145s

********************************
[Compiling module a_inference_run_step_2781387__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 19:31:49.687852: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m35.535996045s

********************************
[Compiling module a_inference_run_step_2781872__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 19:31:50.049675: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m36.942678122s

********************************
[Compiling module a_inference_run_step_2781664__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 19:31:51.468844: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m38.262799014s

********************************
[Compiling module a_inference_run_step_2781616__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 19:31:52.816086: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m38.758730337s

********************************
[Compiling module a_inference_run_step_2781863__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 19:34:31.395838: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_2781270__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 19:34:40.422572: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_2781387__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 19:34:43.140100: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_2781865__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 19:34:43.202435: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_2781616__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 19:34:43.567947: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_2781863__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 19:35:49.431079: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m18.035418833s

********************************
[Compiling module a_inference_run_step_2781270__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 19:35:54.853355: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m11.651000136s

********************************
[Compiling module a_inference_run_step_2781616__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 19:35:58.548677: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m14.980805976s

********************************
[Compiling module a_inference_run_step_2781863__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 19:36:18.945233: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m35.805356682s

********************************
[Compiling module a_inference_run_step_2781865__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 19:37:07.036619: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m26.614190117s

********************************
[Compiling module a_inference_run_step_2781387__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 20:11:17.769404: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [108]
	 [[{{node Placeholder/_1}}]]
2023-05-07 20:11:17.776650: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [42,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 20:11:17.792846: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [97]
	 [[{{node Placeholder/_1}}]]
2023-05-07 20:11:17.800585: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [105,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 20:11:17.808382: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [109,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 20:26:01.795006: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_3165667__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 20:26:04.901282: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_3165781__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 20:26:07.066610: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_3165777__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 20:26:07.629042: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_3165860__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 20:26:07.882487: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_3165939__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 20:28:40.627649: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m32.998720291s

********************************
[Compiling module a_inference_run_step_3165860__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 20:28:55.034943: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m50.133743779s

********************************
[Compiling module a_inference_run_step_3165781__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 20:28:57.442812: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m50.376323914s

********************************
[Compiling module a_inference_run_step_3165777__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 20:29:09.472485: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 5m1.590120556s

********************************
[Compiling module a_inference_run_step_3165939__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 20:29:21.488170: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 5m19.693294937s

********************************
[Compiling module a_inference_run_step_3165667__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 20:31:57.733291: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_3165860__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 20:32:07.676661: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_3165777__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 20:32:13.341236: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_3165781__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 20:32:38.358084: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_3165667__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 20:33:43.027088: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m29.686271032s

********************************
[Compiling module a_inference_run_step_3165781__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 20:33:47.295276: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m49.562152129s

********************************
[Compiling module a_inference_run_step_3165860__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 20:33:48.564057: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m40.887498014s

********************************
[Compiling module a_inference_run_step_3165777__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 20:34:14.200789: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m35.843041349s

********************************
[Compiling module a_inference_run_step_3165667__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 20:50:21.375678: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [101,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 20:50:21.382800: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [78]
	 [[{{node Placeholder/_1}}]]
2023-05-07 20:50:21.390764: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [100,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 20:50:21.390940: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [84]
	 [[{{node Placeholder/_1}}]]
2023-05-07 20:50:21.399962: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [106]
	 [[{{node Placeholder/_1}}]]
2023-05-07 20:50:21.404471: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [104,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 21:03:52.699753: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_3608528__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 21:03:55.575192: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_3608716__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 21:03:57.046085: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_3608530__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 21:03:57.163254: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_3608771__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 21:03:57.350608: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_3608703__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 21:04:01.417670: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_3608707__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 21:04:48.813603: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m56.113990667s

********************************
[Compiling module a_inference_run_step_3608528__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 21:04:52.959600: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m55.796422686s

********************************
[Compiling module a_inference_run_step_3608771__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 21:04:58.721590: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m3.146484098s

********************************
[Compiling module a_inference_run_step_3608716__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 21:05:07.265447: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m5.847927305s

********************************
[Compiling module a_inference_run_step_3608707__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 21:05:23.831512: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m26.480979921s

********************************
[Compiling module a_inference_run_step_3608703__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 21:05:35.209599: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m38.163706782s

********************************
[Compiling module a_inference_run_step_3608530__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 21:07:20.219500: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_3608528__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 21:07:30.246826: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_3608716__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 21:07:44.881339: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_3608707__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 21:07:56.199377: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_3608703__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 21:08:07.161858: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m46.942562458s

********************************
[Compiling module a_inference_run_step_3608528__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 21:08:08.480960: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_3608530__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 21:08:16.849263: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m46.60259084s

********************************
[Compiling module a_inference_run_step_3608716__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 21:08:39.664042: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m43.464730662s

********************************
[Compiling module a_inference_run_step_3608703__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 21:09:50.391767: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m5.510608274s

********************************
[Compiling module a_inference_run_step_3608707__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 21:10:06.087367: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m57.606506902s

********************************
[Compiling module a_inference_run_step_3608530__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 21:32:52.211068: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [108]
	 [[{{node Placeholder/_1}}]]
2023-05-07 21:32:52.214050: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [70]
	 [[{{node Placeholder/_1}}]]
2023-05-07 21:32:52.232436: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [99]
	 [[{{node Placeholder/_1}}]]
2023-05-07 21:32:52.238381: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [101]
	 [[{{node Placeholder/_1}}]]
2023-05-07 21:44:15.135137: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_3926001__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 21:44:20.712914: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_3926155__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 21:44:21.713085: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_3926080__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 21:44:23.384716: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_3926186__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 21:46:14.215024: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m59.080120467s

********************************
[Compiling module a_inference_run_step_3926001__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 21:47:01.875391: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m41.162670737s

********************************
[Compiling module a_inference_run_step_3926155__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 21:47:26.373275: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 5m4.660351849s

********************************
[Compiling module a_inference_run_step_3926080__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 21:48:19.565565: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 5m56.180937043s

********************************
[Compiling module a_inference_run_step_3926186__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 21:49:39.251568: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_3926001__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 21:50:19.276229: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_3926155__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 21:52:08.568032: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_3926186__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 21:53:40.466610: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 5m21.210534459s

********************************
[Compiling module a_inference_run_step_3926155__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 21:54:12.025143: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 6m32.77374572s

********************************
[Compiling module a_inference_run_step_3926001__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 21:56:38.171888: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 6m29.604072639s

********************************
[Compiling module a_inference_run_step_3926186__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 22:18:01.374961: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [115,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 22:18:01.386954: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [109]
	 [[{{node Placeholder/_1}}]]
2023-05-07 22:18:01.392853: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [107]
	 [[{{node Placeholder/_1}}]]
2023-05-07 22:18:01.393681: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [110,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 22:18:01.400400: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [107]
	 [[{{node Placeholder/_1}}]]
2023-05-07 22:31:56.812933: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_4309166__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 22:32:03.735272: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_4309307__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 22:32:08.011099: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_4309473__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 22:32:09.171877: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_4309233__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 22:32:12.213965: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_4309391__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 22:33:43.298780: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m46.486819584s

********************************
[Compiling module a_inference_run_step_4309166__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 22:34:00.976588: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m52.965566891s

********************************
[Compiling module a_inference_run_step_4309473__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 22:34:34.018185: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m21.804418761s

********************************
[Compiling module a_inference_run_step_4309391__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 22:34:38.400311: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m34.665119655s

********************************
[Compiling module a_inference_run_step_4309307__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 22:35:26.062065: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 5m16.891618951s

********************************
[Compiling module a_inference_run_step_4309233__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 22:36:53.184785: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_4309166__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 22:37:53.972941: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_4309307__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 22:38:58.475632: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_4309233__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 22:39:22.365520: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m29.180903091s

********************************
[Compiling module a_inference_run_step_4309166__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 22:41:48.842176: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 5m54.869395238s

********************************
[Compiling module a_inference_run_step_4309307__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 22:42:06.103558: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 5m7.633130546s

********************************
[Compiling module a_inference_run_step_4309233__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 23:05:26.032854: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [93]
	 [[{{node Placeholder/_1}}]]
2023-05-07 23:05:26.059401: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [106]
	 [[{{node Placeholder/_1}}]]
2023-05-07 23:05:26.059826: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [106]
	 [[{{node Placeholder/_1}}]]
2023-05-07 23:05:26.062723: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [68]
	 [[{{node Placeholder/_1}}]]
2023-05-07 23:05:26.074966: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [103,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-07 23:18:58.704426: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_4692789__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 23:18:59.982777: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_4692647__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 23:19:01.196298: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_4692782__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 23:19:01.785802: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_4692886__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 23:19:02.398445: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_4692762__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 23:21:34.888296: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m33.102556782s

********************************
[Compiling module a_inference_run_step_4692886__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 23:21:39.292942: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m36.894630429s

********************************
[Compiling module a_inference_run_step_4692762__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 23:21:45.379828: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m45.39718465s

********************************
[Compiling module a_inference_run_step_4692647__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 23:21:48.800403: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m47.604355222s

********************************
[Compiling module a_inference_run_step_4692782__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 23:22:00.145322: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 5m1.441105178s

********************************
[Compiling module a_inference_run_step_4692789__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 23:24:57.026770: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_4692762__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 23:25:00.029744: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_4692647__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 23:25:00.312425: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_4692886__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 23:25:03.419287: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_4692782__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 23:25:13.885282: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_4692789__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 23:26:04.869998: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m7.843455402s

********************************
[Compiling module a_inference_run_step_4692762__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 23:26:04.951570: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m1.53245103s

********************************
[Compiling module a_inference_run_step_4692782__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 23:26:13.504899: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m13.479865931s

********************************
[Compiling module a_inference_run_step_4692647__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 23:27:14.566912: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m0.685157412s

********************************
[Compiling module a_inference_run_step_4692789__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 23:27:21.149160: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m20.837547254s

********************************
[Compiling module a_inference_run_step_4692886__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 23:43:40.804760: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [72]
	 [[{{node Placeholder/_1}}]]
2023-05-07 23:48:40.527605: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_4831045__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 23:51:26.296014: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m45.768586181s

********************************
[Compiling module a_inference_run_step_4831045__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 23:54:53.980480: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_4831045__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-07 23:58:20.820621: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 5m26.840526624s

********************************
[Compiling module a_inference_run_step_4831045__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 00:18:37.626154: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [96,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-08 00:18:37.631092: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [100,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-08 00:18:37.674058: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [84]
	 [[{{node Placeholder/_1}}]]
2023-05-08 00:18:37.676086: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [103]
	 [[{{node Placeholder/_1}}]]
2023-05-08 00:18:37.678821: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [96]
	 [[{{node Placeholder/_1}}]]
2023-05-08 00:18:37.682025: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [94]
	 [[{{node Placeholder/_1}}]]
2023-05-08 00:32:44.595577: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_5282544__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 00:32:45.367564: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_5282665__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 00:32:47.510526: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_5282850__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 00:32:48.435694: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_5283023__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 00:32:48.600601: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_5282846__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 00:32:50.929328: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_5282824__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 00:33:43.850414: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m58.483291417s

********************************
[Compiling module a_inference_run_step_5282665__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 00:33:44.462962: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m59.867619707s

********************************
[Compiling module a_inference_run_step_5282544__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 00:33:48.391496: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2m59.956026289s

********************************
[Compiling module a_inference_run_step_5283023__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 00:33:53.309889: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m4.709826775s

********************************
[Compiling module a_inference_run_step_5282846__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 00:34:01.070863: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m13.560489478s

********************************
[Compiling module a_inference_run_step_5282850__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 00:34:16.021255: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m25.092360704s

********************************
[Compiling module a_inference_run_step_5282824__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 00:36:25.141169: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_5282544__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 00:36:32.517595: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_5282846__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 00:36:36.964183: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_5283023__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 00:36:37.237795: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_5282850__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 00:37:31.808959: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m6.667997499s

********************************
[Compiling module a_inference_run_step_5282544__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 00:37:44.404305: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m7.166580033s

********************************
[Compiling module a_inference_run_step_5282850__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 00:37:56.257726: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m19.293820039s

********************************
[Compiling module a_inference_run_step_5283023__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 00:38:56.174369: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m23.656847647s

********************************
[Compiling module a_inference_run_step_5282846__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 00:39:17.096451: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m25.687442648s

********************************
[Compiling module a_inference_run_step_5282824__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 00:56:55.646006: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [87]
	 [[{{node Placeholder/_1}}]]
2023-05-08 00:56:55.657040: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [103]
	 [[{{node Placeholder/_1}}]]
2023-05-08 00:56:55.672393: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [106]
	 [[{{node Placeholder/_1}}]]
2023-05-08 00:56:55.672853: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [103]
	 [[{{node Placeholder/_1}}]]
2023-05-08 01:06:59.756746: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_5599639__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 01:07:00.595174: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_5599780__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 01:07:05.665296: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_5599709__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 01:07:10.004111: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_5599781__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 01:09:43.116099: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m43.359529136s

********************************
[Compiling module a_inference_run_step_5599639__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 01:09:58.912703: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m53.24816587s

********************************
[Compiling module a_inference_run_step_5599709__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 01:10:00.467165: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m59.872164392s

********************************
[Compiling module a_inference_run_step_5599780__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 01:10:43.815367: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 5m33.811354784s

********************************
[Compiling module a_inference_run_step_5599781__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 01:13:18.846357: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_5599639__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 01:13:30.848050: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_5599709__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 01:13:32.196034: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_5599780__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 01:14:12.896308: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_5599781__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 01:16:40.672282: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 5m8.476416652s

********************************
[Compiling module a_inference_run_step_5599780__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 01:16:53.218846: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 5m34.373718451s

********************************
[Compiling module a_inference_run_step_5599639__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 01:16:57.519195: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m44.622989883s

********************************
[Compiling module a_inference_run_step_5599781__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 01:17:54.259123: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 6m23.41121946s

********************************
[Compiling module a_inference_run_step_5599709__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 01:35:03.564585: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [93]
	 [[{{node Placeholder/_1}}]]
2023-05-08 01:39:55.794028: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_5741423__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 01:43:25.164261: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 5m29.3704371s

********************************
[Compiling module a_inference_run_step_5741423__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 01:47:09.254949: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_5741423__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 01:50:30.734257: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 5m21.479742164s

********************************
[Compiling module a_inference_run_step_5741423__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 02:09:09.181807: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [102,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-08 02:09:09.217741: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [115]
	 [[{{node Placeholder/_1}}]]
2023-05-08 02:16:03.091023: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_5948368__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 02:16:04.442958: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_5948456__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 02:19:09.623241: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 5m5.180448479s

********************************
[Compiling module a_inference_run_step_5948456__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 02:19:53.777102: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 5m50.686173516s

********************************
[Compiling module a_inference_run_step_5948368__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 02:23:52.895524: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_5948368__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 02:27:12.554115: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 5m19.662682065s

********************************
[Compiling module a_inference_run_step_5948368__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 02:48:09.952069: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [73]
	 [[{{node Placeholder/_1}}]]
2023-05-08 02:48:09.979115: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [112]
	 [[{{node Placeholder/_1}}]]
2023-05-08 02:48:10.048247: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [106,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-08 02:48:10.056422: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [106,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-08 02:58:42.978243: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_6276772__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 02:58:43.272623: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_6276691__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 02:58:50.212630: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_6276860__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 02:58:52.109562: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_6276852__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 03:02:08.689806: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 5m25.41726739s

********************************
[Compiling module a_inference_run_step_6276691__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 03:02:41.810787: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 5m58.83816988s

********************************
[Compiling module a_inference_run_step_6276772__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 03:03:16.193528: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 6m25.980967358s

********************************
[Compiling module a_inference_run_step_6276860__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 03:03:31.055119: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 6m38.945982096s

********************************
[Compiling module a_inference_run_step_6276852__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 03:05:24.589866: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_6276691__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 03:05:49.710515: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_6276772__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 03:06:20.387216: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_6276860__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 03:06:24.803514: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_6276852__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 03:07:37.101594: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m12.512028808s

********************************
[Compiling module a_inference_run_step_6276691__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 03:09:18.245270: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m53.441846397s

********************************
[Compiling module a_inference_run_step_6276852__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 03:09:24.281953: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 5m3.894956727s

********************************
[Compiling module a_inference_run_step_6276860__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 03:09:25.771236: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 5m36.060966897s

********************************
[Compiling module a_inference_run_step_6276772__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 03:21:49.278471: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [114,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-08 03:26:23.188579: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_6417011__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 03:29:09.838531: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m46.650176593s

********************************
[Compiling module a_inference_run_step_6417011__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 03:32:55.269681: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_6417011__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 03:36:10.560276: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 5m15.291120597s

********************************
[Compiling module a_inference_run_step_6417011__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 03:58:26.839438: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [74]
	 [[{{node Placeholder/_1}}]]
2023-05-08 03:58:26.841944: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [84]
	 [[{{node Placeholder/_1}}]]
2023-05-08 04:06:33.268317: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_6626547__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 04:06:34.724452: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_6626455__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 04:09:52.145059: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 5m18.878989555s

********************************
[Compiling module a_inference_run_step_6626547__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 04:11:18.937110: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 6m44.212730442s

********************************
[Compiling module a_inference_run_step_6626455__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 04:13:30.343636: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_6626547__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 04:15:01.401060: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_6626455__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 04:17:16.878594: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 5m46.535116551s

********************************
[Compiling module a_inference_run_step_6626547__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 04:18:51.495769: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 5m50.09488452s

********************************
[Compiling module a_inference_run_step_6626455__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 05:20:54.688476: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [75,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-08 05:20:54.763067: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [16,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-08 05:31:10.923642: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_6923269__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 05:31:26.426090: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_6923354__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 05:36:00.968183: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 6m50.045540196s

********************************
[Compiling module a_inference_run_step_6923269__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 05:36:03.023753: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 6m36.597776224s

********************************
[Compiling module a_inference_run_step_6923354__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 05:39:21.080866: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_6923354__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 05:47:00.574419: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 9m39.493674748s

********************************
[Compiling module a_inference_run_step_6923354__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 05:54:00.738293: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [54]
	 [[{{node Placeholder/_1}}]]
2023-05-08 05:54:00.738628: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [98]
	 [[{{node Placeholder/_1}}]]
2023-05-08 06:01:03.326027: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_7124204__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 06:01:03.667711: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_7124261__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 06:05:11.043022: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 6m7.717151179s

********************************
[Compiling module a_inference_run_step_7124204__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 06:05:48.346718: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 6m44.681289222s

********************************
[Compiling module a_inference_run_step_7124261__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 06:09:08.542644: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_7124204__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 06:09:34.548064: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_7124261__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 06:13:46.910719: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 6m38.371063492s

********************************
[Compiling module a_inference_run_step_7124204__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 06:14:57.773840: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 7m23.22613724s

********************************
[Compiling module a_inference_run_step_7124261__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 07:20:02.530864: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [95,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-08 07:20:02.542499: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [91]
	 [[{{node Placeholder/_1}}]]
2023-05-08 07:28:40.971598: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_7419012__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 07:28:46.360435: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_7419079__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 07:31:04.903624: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m23.932279507s

********************************
[Compiling module a_inference_run_step_7419012__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 07:33:09.888156: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 6m23.527875316s

********************************
[Compiling module a_inference_run_step_7419079__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 07:34:01.390310: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_7419012__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 07:37:30.617766: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 5m29.22802385s

********************************
[Compiling module a_inference_run_step_7419012__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 08:14:42.297687: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [75,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-08 08:14:42.348125: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [101,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-08 08:20:12.183966: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_7624038__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 08:20:14.433762: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_7624126__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 08:21:26.803091: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m14.619262567s

********************************
[Compiling module a_inference_run_step_7624038__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 08:21:48.394133: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m33.96043827s

********************************
[Compiling module a_inference_run_step_7624126__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 08:24:45.288703: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_7624038__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 08:26:52.733293: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m7.444763892s

********************************
[Compiling module a_inference_run_step_7624038__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
2023-05-08 09:58:59.175469: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [93]
	 [[{{node Placeholder/_1}}]]
2023-05-08 10:03:08.590236: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_7938324__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 10:05:43.112573: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m34.522470622s

********************************
[Compiling module a_inference_run_step_7938324__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 10:09:05.868582: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_7938324__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 10:11:36.959942: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m31.091530644s

********************************
[Compiling module a_inference_run_step_7938324__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 10:54:41.171913: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype double and shape [91,28,28]
	 [[{{node Placeholder/_0}}]]
2023-05-08 10:54:41.176467: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [109]
	 [[{{node Placeholder/_1}}]]
2023-05-08 11:00:10.686098: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_8232590__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 11:00:16.214400: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_8232454__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 11:02:41.957934: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m25.743638653s

********************************
[Compiling module a_inference_run_step_8232454__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 11:02:52.414047: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m41.728033704s

********************************
[Compiling module a_inference_run_step_8232590__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 11:06:01.867727: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_8232454__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 11:06:21.992860: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_8232590__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 11:08:28.169017: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m6.176232587s

********************************
[Compiling module a_inference_run_step_8232590__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 11:09:56.860060: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 5m54.992526512s

********************************
[Compiling module a_inference_run_step_8232454__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 12:13:07.365632: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [77]
	 [[{{node Placeholder/_1}}]]
2023-05-08 12:17:15.457434: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_8466809__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 12:19:13.941555: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 3m58.484478907s

********************************
[Compiling module a_inference_run_step_8466809__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 12:22:44.489588: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] 
********************************
[Compiling module a_inference_run_step_8466809__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
2023-05-08 12:25:30.355009: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 4m45.865588328s

********************************
[Compiling module a_inference_run_step_8466809__.65148] Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
********************************
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/lib/function_base.py:492: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  a = np.asanyarray(a)
/home/federico.rubbi/flenv/lib/python3.8/site-packages/numpy/ma/core.py:4285: RuntimeWarning: invalid value encountered in multiply
  self._data.__imul__(np.where(self._mask, self.dtype.type(1),
